{"cells":[{"cell_type":"markdown","metadata":{"id":"qrNuk34O41g9"},"source":["# Localización de fuentes\n","\n","`\n","Autores:\n","Brigitte Aguilar, Sofía Poux, Elizabeth Young\n","`\n","\n","Modificado de *PracticalMEEG2022: MNE-python hands-on tutorial*. Por Britta Westner.\n","\n","\n","El propósito de este tutorial es aprender cómo computar y aplicar un método lineal inverso como MN/dSPM/sLORETA en datos evocados/épocas/crudos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b-ii49rU41hA"},"outputs":[],"source":["\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","import os\n","import numpy as np\n","import mne\n","\n","mne.set_log_level('warning')\n","\n","# Cambiar el siguiente path a la dirección en disco dónde se encuentran los datos\n","data_path = os.path.expanduser(\"~/Documents/MNE-projects/MNE_CuttingEEG_OroVerde/Datos/\")\n","extra_path = os.path.expanduser(\"~/Documents/MNE-projects/MNE_CuttingEEG_OroVerde/Datos/extra_data_mne/\")\n","\n","raw_fname = os.path.join(data_path,\n","   'sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif')\n","epochs_fname = raw_fname.replace('_meg.fif', '-epo.fif')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QYqSSpPi41hC"},"source":["## Lectura de épocas y cómputo de ERP/ERF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAfW2IZf41hD","outputId":"b38847eb-efec-4544-e42d-b0b6255f0711"},"outputs":[],"source":["epochs = mne.read_epochs(epochs_fname)\n","epochs.info\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CmBdDbb441hE","outputId":"feffba28-0a3a-4dc7-fd9b-a3ae767555cb"},"outputs":[],"source":["# Como calculamos el modelo Forward solo con los datos de EEG, vamos a descartar los de MEG.\n","epochs.pick_types(meg=False, eeg=True)\n","\n","print(epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yEDo7bRH41hE"},"outputs":[],"source":["\n","# Para la localización de fuentes es necesario tener la referencia promedio.\n","\n","epochs= mne.set_eeg_reference(epochs, ref_channels='average', projection= True)\n","epochs=epochs[0]\n"]},{"cell_type":"markdown","metadata":{"id":"f3FqLSze41hF"},"source":["Calculemos las respuestas evocadas por dos condiciones: _face_  y  _scrambled_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"koEA5Hp_41hF"},"outputs":[],"source":["evoked_face = epochs['face'].average()\n","evoked_scrambled = epochs['scrambled'].average()"]},{"cell_type":"markdown","metadata":{"id":"_7d_HmzU41hF"},"source":["Contrastemos las dos condiciones:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZgEq76zk41hF","outputId":"56d9ae4c-2b9c-45fe-eaeb-cf5d127f99d8"},"outputs":[],"source":["evoked_contrast = mne.combine_evoked([evoked_face, evoked_scrambled], [0.5, -0.5])\n","evoked_contrast.crop(-0.05, 0.25)\n","evoked_contrast.plot();"]},{"cell_type":"markdown","metadata":{"id":"PQSgmk2X41hG"},"source":["## Preparando el \"beamforming\" de los datos\n","\n","Para la formación de los haces, necesitamos la  **matriz de covarianza de los datos**.\n","\n","Dado que queremos contrastar condiciones, necesitaremos el llamado **common spatial filter**, lo que significa que usaremos la matriz de covarianza que fue computada para ambas condiciones en conjunto. En este caso, eso es para todos los datos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqEmsc1Q41hG"},"outputs":[],"source":["data_cov = mne.compute_covariance(epochs, tmin=0., tmax=0.25,\n","                                  method='empirical', rank='info')"]},{"cell_type":"markdown","metadata":{"id":"H1fXx23d41hG"},"source":["Visualicemos ahora nuestras matrices de covarianza. Vemos que tienen una severa deficiencia de rango. ¿Pueden adivinar por qué?\n","\n","Tomemos una nota mental de que nos tenemos que ocupar de eso más tarde!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJlGsdvc41hH","outputId":"e8c08922-788f-4843-df76-ac702e19f877"},"outputs":[],"source":["mne.viz.plot_cov(data_cov, info=epochs.info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9eeZrF041hH"},"outputs":[],"source":["ranks = {'eeg': 67}  # Pasaremos el rango al \"beamformer\" luego"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EhRKLh9U41hH"},"outputs":[],"source":["# noise_cov = mne.compute_covariance(epochs, tmin=-.25, tmax=0.,  # use the baseline\n","#                                    method='empirical',\n","#                                    rank='info')"]},{"cell_type":"markdown","metadata":{"id":"1rDYUyAt41hH"},"source":["Por último, también necesitamos el \"forward model\" que guardamos en el tutorial anterior"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5z6BIl041hH"},"outputs":[],"source":["fwd_fname = os.path.join(extra_path,\n","    'source_recon/sub-01/prueba-eeg--fwd.fif')\n","fwd = mne.read_forward_solution(fwd_fname)\n","\n","# Restrict forward solution to MEG channels only\n","fwd = mne.pick_types_forward(fwd, meg=False , eeg=True)"]},{"cell_type":"markdown","metadata":{"id":"jRH1WHVw41hI"},"source":["## Cálculo de \"beamformer\" y aplicación a los datos evocados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"riidWqJH41hI"},"outputs":[],"source":["from mne.beamformer import make_lcmv, apply_lcmv"]},{"cell_type":"markdown","metadata":{"id":"a5JEI8f641hI"},"source":["Ahora calcularemos el \"beamformer\":"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adPFgrak41hI"},"outputs":[],"source":["filters = make_lcmv(\n","    epochs.info, fwd,\n","    data_cov=data_cov, noise_cov=None,\n","    pick_ori='max-power', rank=ranks\n",")\n","\n","# noise_cov era igual a la matrz de covarianza que habían definido antes, pero como supuestamente no se necesita para EEG porque no tenés distintos tipos de sensores como en MEG"]},{"cell_type":"markdown","metadata":{"id":"NCqOpVgY41hI"},"source":["Podemos aplicar el filtro a una de nuestras condiciones para ver la activación que sigue a la presentación de una imagen:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Kkv6Ji641hI"},"outputs":[],"source":["stc_face = apply_lcmv(evoked=evoked_face, filters=filters)"]},{"cell_type":"markdown","metadata":{"id":"6Yxn-qmu41hI"},"source":["Podemos graficar el cerebro y el curso temporal usando `stc_face.plot()`. Pueden explorar la reconstrucción de fuentes, por ejemplo mirando la activación como si fuera un video.  \n","\n","Recortamos el objeto `stc` en el tiempo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NXdrMFXA41hI","outputId":"6335b8d9-42b5-4ea9-92f0-633652360adc"},"outputs":[],"source":["subjects_dir = os.path.join(extra_path, 'freesurfer')\n","stc_face.crop(-0.05, 0.25).plot(subjects_dir=subjects_dir, subject='fsaverage', hemi='both')"]},{"cell_type":"markdown","metadata":{"id":"KhNNQtBC41hJ"},"source":["<div class=\"alert alert-success\">\n","    <b>EJERCICIO</b>:\n","     <ul>\n","      <li>En la reconstrucción: ¿qué significan las activaciones positivas y negativas? </li>\n","    </ul>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"N0ATS1C041hJ"},"source":["Apliquemos el mismo filtro a nuestro contraste entre condiciones y grafiquemos:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KUqNtDPD41hJ","outputId":"957a6a2c-ed22-49b1-e1ce-a5328774ecda"},"outputs":[],"source":["%matplotlib qt\n","stc_contrast = apply_lcmv(evoked=evoked_contrast, filters=filters)\n","stc_contrast.plot(subjects_dir=subjects_dir, subject='fsaverage', hemi='both')"]},{"cell_type":"markdown","metadata":{"id":"ze7SyEeI41hJ"},"source":["<div class=\"alert alert-success\">\n","    <b>EJERCICIO</b>:\n","     <ul>\n","      <li>¿Las activaciones positivas y negativas significan lo mismo que antes?</li>\n","      <li>¿Pueden guarda una captura de pantalla de la actividad a 170 ms? </li>\n","    </ul>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"sOtQTGDa41hJ"},"source":["## Preparándonos para la Estimación de Norma Mínima (Minimum Norm Estimation)\n","\n","Para calcular nuestro operador inverso para nuestra estimación (minimum norm estimation), necesitamos una matriz de covarianza del ruido. Vamos a calcular la matriz de covarianza con diferentes métodos y vamos a dejar que el algoritmo elija la mejor!\n","\n","Para más información, chequear:\n","\n","Engemann DA & Gramfort A (2015): Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals, NeuroImage."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmi2hi5N41hJ","outputId":"38f9d7a7-ca66-4f43-e1df-030574d7d965"},"outputs":[],"source":["noise_cov = mne.compute_covariance(epochs, tmax=0.,\n","                                   method=['shrunk', 'empirical'],\n","                                   rank='info')\n","noise_cov['method']"]},{"cell_type":"markdown","metadata":{"id":"lVVYj4Lx41hJ"},"source":["Podemos visualizar el blanqueo de los datos evocados, usando la matriz de covarianza del ruido:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hdCMjVFK41hJ","outputId":"8eeb5252-2435-4558-cb49-4a3457c970ff"},"outputs":[],"source":["%matplotlib inline\n","evoked_contrast.plot_white(noise_cov);"]},{"cell_type":"markdown","metadata":{"id":"qRoo68p141hK"},"source":["Para la solución de fuentes de MNE, queremos usar un operador \"forward\" fijo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5AdejU2641hK"},"outputs":[],"source":["fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=True)"]},{"cell_type":"markdown","metadata":{"id":"jLcajmju41hK"},"source":["## Cómputo del operador inverso y aplicación a los datos evocados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3e5jWfW141hK"},"outputs":[],"source":["from mne.minimum_norm import (make_inverse_operator, apply_inverse)"]},{"cell_type":"markdown","metadata":{"id":"Mw-t4ZSA41hL"},"source":["Los Modelos Inversos de Norma Mínima son independientes de los datos (ya que usan la covarianza del ruido, pero no la matriz de covarianza de los datos) y por lo tanto pueden ser pre-computados y aplicados a los datos en una etapa tardía.\n","\n","No necesitamos tener especial cuidado de nuestras condiciones en este punto.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FogyKnk41hL"},"outputs":[],"source":["info = evoked_contrast.info\n","inverse_operator = make_inverse_operator(info, fwd_fixed, noise_cov,\n","                                         loose=0.2, depth=0.8)"]},{"cell_type":"markdown","metadata":{"id":"q9kjPAOW41hL"},"source":["Apliquemos ahora nuestro operador inverso a nuestros datos evocados de contraste:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dg3cDPCQ41hM","outputId":"732f4bc1-3820-4ea6-aea3-14e05905c881"},"outputs":[],"source":["method = \"dSPM\"\n","snr = 3.\n","lambda2 = 1. / snr ** 2  # regularización\n","stc = apply_inverse(evoked_contrast, inverse_operator, lambda2,\n","                    method=method, pick_ori=None)\n","print(stc)"]},{"cell_type":"markdown","metadata":{"id":"eUtFz7Qz41hM"},"source":["Grafiquemos los resultados como hicimos antes con el beamformer:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eRuhZ9gc41hM","outputId":"bbe3710f-d586-41fa-d218-d7686266cb52"},"outputs":[],"source":["subjects_dir = os.path.join(extra_path, 'freesurfer')\n","stc.plot(hemi='both', subjects_dir=subjects_dir, subject='fsaverage')"]},{"cell_type":"markdown","metadata":{"id":"JSTrVtXd41hM"},"source":["## Unificándo los datos a un cerebro promedio para estudio de grupos"]},{"cell_type":"markdown","metadata":{"id":"0K6_U6DR41hM"},"source":["Dependiendo de tu instalación de MNE-Python, esto podría descargar los datos de *fsaverage*. Esto podría demorar un rato."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gnig5dm141hM","outputId":"43dd3689-d66e-4d70-da3f-8dee22fb2da9"},"outputs":[],"source":["mne.datasets.fetch_fsaverage(subjects_dir=subjects_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QQpEKDca41hN"},"outputs":[],"source":["morph = mne.compute_source_morph(stc, subject_from='fsaverage',\n","                                 subject_to='fsaverage',\n","                                 subjects_dir=subjects_dir)\n","stc_fsaverage = morph.apply(stc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7wIEbXbZ41hN","outputId":"a4d242ff-72d3-43c3-c01f-4df66ba2fe9c"},"outputs":[],"source":["stc_fsaverage.plot(surface='inflated', hemi='both',\n","                   subjects_dir=subjects_dir)\n"]},{"cell_type":"markdown","metadata":{"id":"9ZznXNdY41hN"},"source":["<div class=\"alert alert-success\">\n","    <b>EJERCICIO</b>:\n","     <ul>\n","      <li>Correr sLORETA sobre los mismos datos y comparar la localización de fuentes. </li>\n","    </ul>\n","</div>\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"mne","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
