{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Análisis de grupos con MNE-Python\n",
    "\n",
    "\n",
    "El objetivo de este tutorial es mostrar cómo hacer análisis de grupos con MNE-Python.\n",
    "\n",
    "    Autores: Brigitte Aguilar, Sofía Poux, Elizabeth Young\n",
    "    Modificado de: Britta Westner, Alexandre Gramfort, Denis A. Engemann, Mainak Jas, Hicham Janati\n",
    "\n",
    "    Licencia: BSD (claúsula 3)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "mne.set_log_level('error')\n",
    "\n",
    "# Cambie la siguiente ruta a donde está la carpeta 'extra_data_mne' dentro de la carpeta 'Datos' en su disco:\n",
    "extra_path = os.path.expanduser('~/Documents/MNE-projects/mne_tutorial_GardenOroVerde/Datos/extra_data_mne')\n",
    "evokeds_path = os.path.join(extra_path, 'group_analysis/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos si la configuración de la ruta es correcta y si los datos están ahí:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ls $evokeds_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets evocados\n",
    "\n",
    "Tenemos los datos evocados para todos los participantes. Sin embargo, los datos de un participante (dataset # 10) tienen problemas con los triggers que necesitan ser arreglados antes de trabajar con ellos, por lo tanto, por ahora, vamos a descartar los datos de ese participante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['sub-%02d' % ii for ii in range(1, 17) if ii not in [10]]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos nuestros datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los datasets uno por uno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'sub-02'\n",
    "fname = os.path.join(evokeds_path, ('%s_list-ave.fif' % subject))\n",
    "evokeds = mne.read_evokeds(fname, verbose=False)\n",
    "evokeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué son los objetos evoked? Los objetos evocados o evoked normalmente almacenan señales EEG o MEG que se han promediado a lo largo de múltiples épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "evokeds[0].plot_joint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los join plots combinan gráficos de mariposas con topografías y proporcionan un excelente primer vistazo a los datos evocados; de forma predeterminada, las topografías se colocarán automáticamente según los picos encontrados. Aquí trazamos la condición \"famous\"; si no se especifican tipos de canales (con picks), obtenemos una gráfica separada para cada tipo de sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos recorrer todos los datasets para obtener una descripción general y de esta manera observar si hay algún dataset poblemático:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ch_type = 'eeg'  # elegimos los canales de EEG\n",
    "conditions = ['famous', 'unfamiliar', 'scrambled']\n",
    "\n",
    "f, axes = plt.subplots(4, 4, figsize=(13, 9), sharex=True, sharey=True)\n",
    "\n",
    "for ax, subject in zip(axes.ravel(), datasets):\n",
    "    evokeds_dict = dict()\n",
    "    fname = os.path.join(evokeds_path, ('%s_list-ave.fif' % subject))\n",
    "    evokeds = mne.read_evokeds(fname)\n",
    "    evokeds = [ev for ev in evokeds if ev.comment in conditions]\n",
    "    for condition, ev in zip(conditions, evokeds):\n",
    "        evokeds_dict[condition] = ev.crop(tmin=-0.3, tmax=0.6)\n",
    "    mne.viz.plot_compare_evokeds(evokeds_dict, picks=ch_type, show=False,\n",
    "                                 axes=ax, title=subject)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué significa GFP? Global Field Power (GFP) es una medida de la (no)uniformidad del campo electromagnético en los sensores. Normalmente se calcula como la desviación estándar de los valores del sensor en cada momento. Por lo tanto, es una serie temporal unidimensional que captura la variabilidad espacial de la señal en las ubicaciones de los sensores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "    <b>EJERCICIO</b>:\n",
    "     <ul>\n",
    "      <li>Realizar los mismos gráficos GFP para el caso de magnetómetros</li>\n",
    "      <li>¿Observas algún dataset problemático?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer todos los datos y calcular contraste\n",
    "\n",
    "Ahora, leeremos todos los datasets y los apilaremos en _una lista_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds_list = []\n",
    "\n",
    "for subject in datasets:\n",
    "    fname = os.path.join(evokeds_path, ('%s_list-ave.fif' % subject))\n",
    "    evokeds = mne.read_evokeds(fname)\n",
    "    evokeds = [ev for ev in evokeds if ev.comment in ['famous', 'scrambled']]\n",
    "    evokeds_list.append(evokeds)\n",
    "\n",
    "evokeds_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de aquí, podemos obtener el contraste, por ejemplo entre _famous_ y _scrambled_. Podemos visualizar gráficamente este contraste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_list = []\n",
    "f, axes = plt.subplots(4, 4, figsize=(13, 9), sharex=True, sharey=True)\n",
    "\n",
    "for ax, subject, evokeds in zip(axes.ravel(), datasets, evokeds_list):\n",
    "    contrast = mne.combine_evoked(evokeds, weights=[0.5, -0.5]).crop(-0.3, 0.5)\n",
    "    contrast.comment = 'contrast'\n",
    "    contrast_list.append(contrast)\n",
    "    mne.viz.plot_compare_evokeds(contrast, picks=ch_type, show=False,\n",
    "                                 axes=ax, title=subject)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una mirada al promedio total (grand average)\n",
    "\n",
    "Los _Grand averages_ se obtienen mediante el promedio de los datos del espacio de sensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.grand_average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "evoked_gave = mne.grand_average(contrast_list)\n",
    "evoked_gave.plot_joint();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algunas estadísticas - test de permutación de clústers para un canal\n",
    "\n",
    "Comenzaremos utilizando un único canal, EEG065. \n",
    "\n",
    "Realizaremos un test de permutación de clústers de nuestro contraste contra 0.\n",
    "Comencemos con la configuración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar paquetes para las estadísticas\n",
    "\n",
    "import scipy as sp\n",
    "from mne.stats import permutation_cluster_1samp_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llevemos nuestros datos a una arreglo de numpy para que podamos pasarlo como parámetro a la función de estadísticas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 'EEG065'\n",
    "ch_idx = contrast.ch_names.index(channel)\n",
    "data = np.array([c.data[ch_idx] for c in contrast_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, configuremos algunos parámetros para nuestro test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 1  # Para el número de trabajos paralelos, es posible que desees establecerlo en 1\n",
    "n_permutations = 5000  # número de permutaciones a correr\n",
    "\n",
    "# Especificar la adyacencia de los puntos en los datos: \n",
    "# Aquí, no se necesita una adyacencia especial porque es solo un canal y MNE \n",
    "# simplemente asumirá una cuadrículas regular, lo cual es adecuado para nuestra dimensión de\n",
    "adjacency = None  \n",
    "\n",
    "tail = 0.  # hacemos un test de dos colas (two-sided test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con eso resuelto, establezcamos los umbrales de los clústers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establecer el valor p que queremos utilizar para realizar nuestra prueba\n",
    "p_value = 0.05\n",
    "\n",
    "#Ahora, calculemos el umbral de valor t (threshold) para un valor p dado\n",
    "# y un tipo de prueba (bilateral o unilateral) el cual\n",
    "# necesitamos pasarlo a la función de estadísticas. \n",
    "# Tené en cuenta que esto cambia para una prueba de una cola.\n",
    "deg_of_free = len(data) - 1\n",
    "threshold = sp.stats.t.ppf(1 - p_value/ (1 + (tail == 0)), deg_of_free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos todo para poder realizar nuestras estadísticas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat_fun(H1): min=-6.783906 max=1.635025\n",
      "Running initial clustering …\n",
      "Found 2 clusters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe8d0b4ffa44e9f842fcf7952ea442a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/4999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster_stats = permutation_cluster_1samp_test(\n",
    "    data, \n",
    "    threshold=threshold, \n",
    "    n_jobs=n_jobs, \n",
    "    verbose=True, \n",
    "    tail=tail,\n",
    "    adjacency=adjacency,\n",
    "    n_permutations=n_permutations, \n",
    "    seed=42)\n",
    "\n",
    "T_obs, clusters, cluster_p_values, _ = cluster_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizamos los resultados para el test de un sólo canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuramos la figura:\n",
    "fig, axes = plt.subplots(2, sharex=True)\n",
    "\n",
    "# En el primer eje: graficar los datos (contraste promediado en todos los conjuntos de datos)\n",
    "ax = axes[0]\n",
    "ax.plot(contrast.times, data.mean(axis=0), label='ERP Contrast')\n",
    "ax.set(title='Channel : ' + channel, ylabel='fT/cm')\n",
    "ax.legend()\n",
    "\n",
    "# en el segundo eje:\n",
    "ax = axes[1]\n",
    "# enumerar a través de los clústers\n",
    "for ii, cluster_ii in enumerate(clusters):\n",
    "    c = cluster_ii[0]\n",
    "\n",
    "    # verificar si el valor p coincidente es menor que el umbral:\n",
    "    if cluster_p_values[ii] < p_value:\n",
    "        # Si es así, marcar el período de tiempo:\n",
    "        h1 = ax.axvspan(contrast.times[c[0]], \n",
    "                        contrast.times[c[-1] - 1],\n",
    "                        color='r', alpha=0.3)\n",
    "\n",
    "# graficamos los valores t \n",
    "hf = ax.plot(contrast.times, T_obs, 'g')\n",
    "\n",
    "# establecemos leyenda, ejes y graficamos\n",
    "ax.legend((h1,), (u'p < %s' % p_value,), loc='upper right', ncol=1)\n",
    "ax.set(xlabel='Time (ms)', ylabel='T-values',\n",
    "       ylim=[-10., 10.], xlim=contrast.times[[0, -1]])\n",
    "fig.tight_layout(pad=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de permutación de clústers a través del tiempo y de los sensores\n",
    "\n",
    "Ahora, elijamos un sensor en particular y ejecutemos la permutación de clústers a través de los _magnetómetros_: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí podemos utilizar una función conveniente para datos espacio-temporales:\n",
    "from mne.stats import spatio_temporal_cluster_1samp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elijamos los magnetómetros:\n",
    "ch_type = 'mag'\n",
    "\n",
    "# Acá otra vez tenemos que llevar los datos a un array de numpy\n",
    "data = np.array([c.copy().pick_types(meg=ch_type).data\n",
    "                 for c in contrast_list])\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de clústering nos dice:\n",
    "```\n",
    "X : array, shape (n_observations, p[, q], n_vertices)\n",
    "    Los datos que se van a agrupar. La primera dimensión debería corresponder a la diferencia entre muestras emparejadas  (observaciones) en dos condiciones. La segunda y, opcionalmente, la tercera dimensión corresponden a los datos de tiempo o tiempo-frecuencia. Y la última dimensión debería ser espacial.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurémonos que la dimensión espacial es la última:\n",
    "data = np.transpose(data, (0, 2, 1)) \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuramos nuestros parámetros nuevamente. Esta vez debemos prestar mucha atención a la adyacencia!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# umbrales de clusters y nro de colas\n",
    "tail = 0.  # para test de dos colas\n",
    "\n",
    "# configuramos el umbral de clústers\n",
    "deg_of_free = len(data) - 1\n",
    "threshold = sp.stats.t.ppf(1 - p_value/ (1 + (tail == 0)), deg_of_free)\n",
    "\n",
    "# Crear una triangulación entre las ubicaciones de los sensores MEG \n",
    "# para utilizar como información de adyacencia en las estadísticas:\n",
    "adjacency = mne.channels.find_ch_adjacency(contrast.info, ch_type)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_stats = spatio_temporal_cluster_1samp_test(\n",
    "    data, \n",
    "    threshold=threshold, \n",
    "    n_jobs=2, \n",
    "    verbose=True, \n",
    "    tail=tail,\n",
    "    adjacency=adjacency, \n",
    "    out_type='indices',\n",
    "    check_disjoint=True, \n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificamos la salida para que sea más fácil de graficar:\n",
    "T_obs, clusters, p_values, _ = cluster_stats\n",
    "good_cluster_inds = np.where(p_values < 0.05)[0]\n",
    "\n",
    "print(\"Good clusters: %i\" % len(good_cluster_inds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizamos los clústers espacio-temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mne.viz import plot_topomap\n",
    "\n",
    "# algunas configuraciones para la graficación\n",
    "colors = 'r', 'steelblue'\n",
    "linestyles = '-', '--'\n",
    "\n",
    "# encontramos los sensores relevantes\n",
    "pos = mne.find_layout(contrast.info, ch_type=ch_type).pos\n",
    "\n",
    "T_obs_max = 5.\n",
    "T_obs_min = -T_obs_max\n",
    "\n",
    "# blucle sobre los sensores relevantes\n",
    "for i_clu, clu_idx in enumerate(good_cluster_inds):\n",
    "\n",
    "    # desempaquetar la información de clústers, obtener índices únicos por clúster\n",
    "    time_inds, space_inds = np.squeeze(clusters[clu_idx])\n",
    "    ch_inds = np.unique(space_inds)\n",
    "    time_inds = np.unique(time_inds)\n",
    "\n",
    "    # obtener la topografía para estadísticas y promediar a lo largo del tiempo\n",
    "    T_obs_map = T_obs[time_inds, ...].mean(axis=0)\n",
    "\n",
    "    # obtener señales en sensores significativos y promediar a lo largo de los sensores\n",
    "    signals = data[..., ch_inds].mean(axis=-1)\n",
    "    sig_times = contrast.times[time_inds]\n",
    "\n",
    "    # crear una máscara espacial\n",
    "    mask = np.zeros((T_obs_map.shape[0], 1), dtype=bool)\n",
    "    mask[ch_inds, :] = True\n",
    "\n",
    "    # inicializar figura\n",
    "    fig, ax_topo = plt.subplots(1, 1, figsize=(7, 2.))\n",
    "\n",
    "    # marcar los sensores en el clúster\n",
    "    mask_params = dict(marker='.', markerfacecolor='k', markersize=2)\n",
    "\n",
    "    # graficar el promedio de la prueba estadística y marcar los sensores significativos\n",
    "    sel = mne.pick_types(contrast.info, meg=ch_type)\n",
    "    info = mne.pick_info(contrast.info, sel)\n",
    "    image, _ = plot_topomap(T_obs_map, info, ch_type=ch_type, mask=mask, \n",
    "                            axes=ax_topo, sensors=False,\n",
    "                            mask_params=mask_params,\n",
    "                            vlim=(T_obs_min,T_obs_max),\n",
    "                            show=False)\n",
    "\n",
    "    # mostrar en una misma figura la imagen y barra de colores\n",
    "    divider = make_axes_locatable(ax_topo)\n",
    "\n",
    "    # añadir los ejes para la barra de colores y la barra de colores \n",
    "    ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    plt.colorbar(image, cax=ax_colorbar, format='%0.1f')\n",
    "\n",
    "    # etiquetar la topografía\n",
    "    ax_topo.set_xlabel('Averaged t-map\\n({:0.2f} - {:0.2f} ms)'.format(\n",
    "        *sig_times[[0, -1]]\n",
    "    ))\n",
    "\n",
    "    # agregar un nuevo eje para las series de tiempo y graficar las series de tiempo\n",
    "    ax_signals = divider.append_axes('right', size='300%', pad=1.2)\n",
    "    for signal, name, col, ls in zip(signals, ['Contrast'], colors,\n",
    "                                     linestyles):\n",
    "        ax_signals.plot(contrast.times, signal, color=col,\n",
    "                        linestyle=ls, label=name)\n",
    "\n",
    "    # marcar el inicio del estímulo\n",
    "    ax_signals.axvline(0, color='k', linestyle=':', label='stimulus onset')\n",
    "\n",
    "    # ajustar y etiquetar ejes\n",
    "    ax_signals.set_xlim([contrast.times[0], contrast.times[-1]])\n",
    "    ax_signals.set_xlabel('Time [s]')\n",
    "    ax_signals.set_ylabel('Amplitude')\n",
    "\n",
    "    # graficar el rango de tiempo significativo en la serie de tiempo\n",
    "    ymin, ymax = ax_signals.get_ylim()\n",
    "    ax_signals.fill_betweenx((ymin, ymax), sig_times[0], sig_times[-1],\n",
    "                             color='orange', alpha=0.3)\n",
    "    ax_signals.legend(loc='lower right')\n",
    "    title = 'Cluster #{0} (p < {1:0.3f})'.format(i_clu + 1, p_values[clu_idx])\n",
    "    ax_signals.set(ylim=[ymin, ymax], title=title)\n",
    "\n",
    "    # limpiamos la figura un poco\n",
    "    fig.tight_layout(pad=0.5, w_pad=0)\n",
    "    fig.subplots_adjust(bottom=.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecturas adicionales y créditos:\n",
    "\n",
    "El código de esta notebook está fuertemente inspirado en: https://github.com/mne-tools/mne-biomag-group-demo/tree/master/scripts/results/statistics\n",
    "\n",
    "Podés encontrar más información sobre las estadísticas a nivel de sensor aquí: https://mne.tools/stable/auto_tutorials/stats-sensor-space/index.html\n",
    "\n",
    "Si deseas hacer estadísticas en el espacio de las fuentes, aquí más información: https://mne.tools/stable/auto_tutorials/stats-source-space/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('mne_aix')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "96118219f514f0f7c28e51c58abb2aa3e9c527721ceabff83c3dd194a32d9fc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
